{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "form sklearn.linearmodel \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, precision_recall_curve, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vector_df(path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'jarednewstudy'\n",
    "key = 'train_mels_vec.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=bucket_name, Key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_and_not_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m_is_dtype_type\u001b[0;34m(arr_or_dtype, condition)\u001b[0m\n\u001b[1;32m   1905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(tipo)\u001b[0m\n\u001b[1;32m    219\u001b[0m     return lambda tipo: (\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtipo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtipo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-08da1bd4cd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(obj['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_target(df, target):\n",
    "    \"\"\"\n",
    "    Returns y as ndarray, X as a dataframe\n",
    "    \"\"\"\n",
    "    df[target] = pd.get_dummies(df)['labels_{}'.format(target)]\n",
    "    y = df[target].values\n",
    "    X = df.drop(columns=['Unnamed: 0', 'labels', 'fname', target])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = choose_target(df, 'Purr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16384)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "      <th>Bark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-16.349299</td>\n",
       "      <td>-18.031488</td>\n",
       "      <td>-17.434985</td>\n",
       "      <td>-17.300537</td>\n",
       "      <td>-17.570010</td>\n",
       "      <td>-17.667189</td>\n",
       "      <td>-18.032827</td>\n",
       "      <td>-17.449463</td>\n",
       "      <td>-17.705600</td>\n",
       "      <td>-16.719248</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.872248</td>\n",
       "      <td>-54.715844</td>\n",
       "      <td>-54.467296</td>\n",
       "      <td>-54.514963</td>\n",
       "      <td>-54.475302</td>\n",
       "      <td>-54.406091</td>\n",
       "      <td>-54.392383</td>\n",
       "      <td>-54.082551</td>\n",
       "      <td>-54.034307</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>20.127993</td>\n",
       "      <td>20.688209</td>\n",
       "      <td>20.367240</td>\n",
       "      <td>19.875046</td>\n",
       "      <td>20.854102</td>\n",
       "      <td>20.937940</td>\n",
       "      <td>20.514703</td>\n",
       "      <td>20.464548</td>\n",
       "      <td>20.452823</td>\n",
       "      <td>20.091427</td>\n",
       "      <td>...</td>\n",
       "      <td>12.575905</td>\n",
       "      <td>11.814840</td>\n",
       "      <td>11.998541</td>\n",
       "      <td>12.192558</td>\n",
       "      <td>11.897926</td>\n",
       "      <td>11.906986</td>\n",
       "      <td>11.975822</td>\n",
       "      <td>12.247739</td>\n",
       "      <td>11.965737</td>\n",
       "      <td>0.063151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-86.838570</td>\n",
       "      <td>-93.673386</td>\n",
       "      <td>-84.644859</td>\n",
       "      <td>-73.073288</td>\n",
       "      <td>-82.085945</td>\n",
       "      <td>-82.684784</td>\n",
       "      <td>-81.623718</td>\n",
       "      <td>-80.501129</td>\n",
       "      <td>-82.684784</td>\n",
       "      <td>-82.684784</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-98.188225</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-86.038353</td>\n",
       "      <td>-88.565170</td>\n",
       "      <td>-87.100159</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-29.178788</td>\n",
       "      <td>-31.760992</td>\n",
       "      <td>-29.661211</td>\n",
       "      <td>-29.355464</td>\n",
       "      <td>-30.785376</td>\n",
       "      <td>-30.901316</td>\n",
       "      <td>-31.233475</td>\n",
       "      <td>-30.523108</td>\n",
       "      <td>-30.386949</td>\n",
       "      <td>-29.219077</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.786613</td>\n",
       "      <td>-62.226665</td>\n",
       "      <td>-62.337007</td>\n",
       "      <td>-62.346794</td>\n",
       "      <td>-62.325818</td>\n",
       "      <td>-62.276100</td>\n",
       "      <td>-62.276100</td>\n",
       "      <td>-61.809067</td>\n",
       "      <td>-61.838096</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-14.907685</td>\n",
       "      <td>-16.178761</td>\n",
       "      <td>-15.187243</td>\n",
       "      <td>-15.675508</td>\n",
       "      <td>-15.648202</td>\n",
       "      <td>-14.970316</td>\n",
       "      <td>-15.598800</td>\n",
       "      <td>-15.420786</td>\n",
       "      <td>-15.892051</td>\n",
       "      <td>-14.594942</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.025717</td>\n",
       "      <td>-54.517656</td>\n",
       "      <td>-54.192310</td>\n",
       "      <td>-54.426260</td>\n",
       "      <td>-54.097078</td>\n",
       "      <td>-54.230137</td>\n",
       "      <td>-54.210979</td>\n",
       "      <td>-53.630930</td>\n",
       "      <td>-53.744453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-2.247474</td>\n",
       "      <td>-4.087688</td>\n",
       "      <td>-3.802814</td>\n",
       "      <td>-4.690444</td>\n",
       "      <td>-2.832629</td>\n",
       "      <td>-3.688863</td>\n",
       "      <td>-3.928626</td>\n",
       "      <td>-3.223348</td>\n",
       "      <td>-3.495781</td>\n",
       "      <td>-3.097138</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.829165</td>\n",
       "      <td>-47.249040</td>\n",
       "      <td>-47.085740</td>\n",
       "      <td>-47.133106</td>\n",
       "      <td>-46.901263</td>\n",
       "      <td>-47.075775</td>\n",
       "      <td>-47.252785</td>\n",
       "      <td>-46.903483</td>\n",
       "      <td>-46.476848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>37.634338</td>\n",
       "      <td>36.299622</td>\n",
       "      <td>37.215313</td>\n",
       "      <td>35.153126</td>\n",
       "      <td>35.357887</td>\n",
       "      <td>37.711174</td>\n",
       "      <td>35.847908</td>\n",
       "      <td>37.507835</td>\n",
       "      <td>39.096722</td>\n",
       "      <td>39.171272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 16385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean    -16.349299   -18.031488   -17.434985   -17.300537   -17.570010   \n",
       "std      20.127993    20.688209    20.367240    19.875046    20.854102   \n",
       "min     -86.838570   -93.673386   -84.644859   -73.073288   -82.085945   \n",
       "25%     -29.178788   -31.760992   -29.661211   -29.355464   -30.785376   \n",
       "50%     -14.907685   -16.178761   -15.187243   -15.675508   -15.648202   \n",
       "75%      -2.247474    -4.087688    -3.802814    -4.690444    -2.832629   \n",
       "max      37.634338    36.299622    37.215313    35.153126    35.357887   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean    -17.667189   -18.032827   -17.449463   -17.705600   -16.719248  ...   \n",
       "std      20.937940    20.514703    20.464548    20.452823    20.091427  ...   \n",
       "min     -82.684784   -81.623718   -80.501129   -82.684784   -82.684784  ...   \n",
       "25%     -30.901316   -31.233475   -30.523108   -30.386949   -29.219077  ...   \n",
       "50%     -14.970316   -15.598800   -15.420786   -15.892051   -14.594942  ...   \n",
       "75%      -3.688863    -3.928626    -3.223348    -3.495781    -3.097138  ...   \n",
       "max      37.711174    35.847908    37.507835    39.096722    39.171272  ...   \n",
       "\n",
       "             16375        16376        16377        16378        16379  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean    -53.872248   -54.715844   -54.467296   -54.514963   -54.475302   \n",
       "std      12.575905    11.814840    11.998541    12.192558    11.897926   \n",
       "min     -86.038353   -86.038353   -86.038353   -98.188225   -86.038353   \n",
       "25%     -61.786613   -62.226665   -62.337007   -62.346794   -62.325818   \n",
       "50%     -54.025717   -54.517656   -54.192310   -54.426260   -54.097078   \n",
       "75%     -46.829165   -47.249040   -47.085740   -47.133106   -46.901263   \n",
       "max       0.000000     0.000000     0.841981     0.000000     0.000000   \n",
       "\n",
       "             16380        16381        16382        16383         Bark  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean    -54.406091   -54.392383   -54.082551   -54.034307     0.004000  \n",
       "std      11.906986    11.975822    12.247739    11.965737     0.063151  \n",
       "min     -86.038353   -86.038353   -88.565170   -87.100159     0.000000  \n",
       "25%     -62.276100   -62.276100   -61.809067   -61.838096     0.000000  \n",
       "50%     -54.230137   -54.210979   -53.630930   -53.744453     0.000000  \n",
       "75%     -47.075775   -47.252785   -46.903483   -46.476848     0.000000  \n",
       "max       0.000000     0.000000     0.871323     0.000000     1.000000  \n",
       "\n",
       "[8 rows x 16385 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1399            9.17s\n",
      "         2           0.1315            9.02s\n",
      "         3           0.1165            8.91s\n",
      "         4           0.1078            8.97s\n",
      "         5           0.1027            8.93s\n",
      "         6           0.0976            9.21s\n",
      "         7           0.0953            9.04s\n",
      "         8           0.0902            9.60s\n",
      "         9           0.0871           10.41s\n",
      "        10           0.0819           10.71s\n",
      "        20           0.0524           10.63s\n",
      "        30           0.0328            9.78s\n",
      "        40           0.0236            8.98s\n",
      "        50           0.0180            8.32s\n",
      "        60           0.0133            7.67s\n",
      "        70           0.0105            7.03s\n",
      "        80           0.0085            6.44s\n",
      "        90           0.0068            5.87s\n",
      "       100           0.0054            5.29s\n",
      "       200           0.0006            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=3,\n",
       "                           max_features=1000, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=8, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=1,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=0.05,\n",
    "                                n_estimators=200,\n",
    "                                max_features=1000,\n",
    "                                 random_state=8,\n",
    "                                 verbose=1\n",
    "                                )\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = gbc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jared/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jared/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_preds)\n",
    "prec = precision_score(y_test, y_preds)\n",
    "rec = recall_score(y_test, y_preds)\n",
    "f1 = f1_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[y_preds==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "X_pca = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scree_plot(ax, pca, n_components_to_plot=8, title=None):\n",
    "    \"\"\"Make a scree plot showing the variance explained (i.e. varaince of the projections) for the principal components in a fit sklearn PCA object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib.axis object\n",
    "      The axis to make the scree plot on.\n",
    "      \n",
    "    pca: sklearn.decomposition.PCA object.\n",
    "      A fit PCA object.\n",
    "      \n",
    "    n_components_to_plot: int\n",
    "      The number of principal components to display in the skree plot.\n",
    "      \n",
    "    title: str\n",
    "      A title for the skree plot.\n",
    "    \"\"\"\n",
    "    num_components = pca.n_components_\n",
    "    ind = np.arange(num_components)\n",
    "    vals = pca.explained_variance_ratio_\n",
    "    ax.plot(ind, vals, color='blue')\n",
    "    ax.scatter(ind, vals, color='blue', s=50)\n",
    "\n",
    "    for i in range(num_components):\n",
    "        ax.annotate(r\"{:2.2f}%\".format(vals[i]), \n",
    "                   (ind[i]+0.2, vals[i]+0.005), \n",
    "                   va=\"bottom\", \n",
    "                   ha=\"center\", \n",
    "                   fontsize=12)\n",
    "\n",
    "    ax.set_xticklabels(ind, fontsize=12)\n",
    "    ax.set_ylim(0, max(vals) + 0.05)\n",
    "    ax.set_xlim(0 - 0.45, n_components_to_plot + 0.45)\n",
    "    ax.set_xlabel(\"Principal Component\", fontsize=12)\n",
    "    ax.set_ylabel(\"Variance Explained (%)\", fontsize=12)\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scree_plot(ax, pca, title=\"Scree Plot for Digits Principal Components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1, 2])\n",
    "b = np.array([3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A': a, 'B':b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "A  0.0  1.0  2.0  0.0\n",
       "B  3.0  4.0  5.0  6.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=d.values(), index=d.keys()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-9067e2e94b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1244\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit classifier with out-of-bag estimates\n",
    "params = {'n_estimators': 1200, 'max_depth': 3, 'subsample': 0.5,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: {:.4f}\".format(acc))\n",
    "\n",
    "n_estimators = params['n_estimators']\n",
    "x = np.arange(n_estimators) + 1\n",
    "\n",
    "\n",
    "def heldout_score(clf, X_test, y_test):\n",
    "    \"\"\"compute deviance scores on ``X_test`` and ``y_test``. \"\"\"\n",
    "    score = np.zeros((n_estimators,), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        score[i] = clf.loss_(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def cv_estimate(n_folds=3):\n",
    "    cv = KFold(n=X_train.shape[0], n_folds=n_folds)\n",
    "    cv_clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    val_scores = np.zeros((n_estimators,), dtype=np.float64)\n",
    "    for train, test in cv:\n",
    "        cv_clf.fit(X_train[train], y_train[train])\n",
    "        val_scores += heldout_score(cv_clf, X_train[test], y_train[test])\n",
    "    val_scores /= n_folds\n",
    "    return val_scores\n",
    "\n",
    "\n",
    "# Estimate best n_estimator using cross-validation\n",
    "cv_score = cv_estimate(3)\n",
    "\n",
    "# Compute best n_estimator for test data\n",
    "test_score = heldout_score(clf, X_test, y_test)\n",
    "\n",
    "# negative cumulative sum of oob improvements\n",
    "cumsum = -np.cumsum(clf.oob_improvement_)\n",
    "\n",
    "# min loss according to OOB\n",
    "oob_best_iter = x[np.argmin(cumsum)]\n",
    "\n",
    "# min loss according to test (normalize such that first loss is 0)\n",
    "test_score -= test_score[0]\n",
    "test_best_iter = x[np.argmin(test_score)]\n",
    "\n",
    "# min loss according to cv (normalize such that first loss is 0)\n",
    "cv_score -= cv_score[0]\n",
    "cv_best_iter = x[np.argmin(cv_score)]\n",
    "\n",
    "# color brew for the three curves\n",
    "oob_color = list(map(lambda x: x / 256.0, (190, 174, 212)))\n",
    "test_color = list(map(lambda x: x / 256.0, (127, 201, 127)))\n",
    "cv_color = list(map(lambda x: x / 256.0, (253, 192, 134)))\n",
    "\n",
    "# plot curves and vertical lines for best iterations\n",
    "plt.plot(x, cumsum, label='OOB loss', color=oob_color)\n",
    "plt.plot(x, test_score, label='Test loss', color=test_color)\n",
    "plt.plot(x, cv_score, label='CV loss', color=cv_color)\n",
    "plt.axvline(x=oob_best_iter, color=oob_color)\n",
    "plt.axvline(x=test_best_iter, color=test_color)\n",
    "plt.axvline(x=cv_best_iter, color=cv_color)\n",
    "\n",
    "# add three vertical lines to xticks\n",
    "xticks = plt.xticks()\n",
    "xticks_pos = np.array(xticks[0].tolist() +\n",
    "                      [oob_best_iter, cv_best_iter, test_best_iter])\n",
    "xticks_label = np.array(list(map(lambda t: int(t), xticks[0])) +\n",
    "                        ['OOB', 'CV', 'Test'])\n",
    "ind = np.argsort(xticks_pos)\n",
    "xticks_pos = xticks_pos[ind]\n",
    "xticks_label = xticks_label[ind]\n",
    "plt.xticks(xticks_pos, xticks_label)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('normalized loss')\n",
    "plt.xlabel('number of iterations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
