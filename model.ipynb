{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, precision_recall_curve, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'jarednewstudy'\n",
    "key = 'train_mels_vec.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=bucket_name, Key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(obj['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = pd.read_csv(obj['Body'], iterator=True, chunksize=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_windows_mel.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(tp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19868, 12901)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_target(df, target, fill_na):\n",
    "    \"\"\"\n",
    "    Returns y as ndarray, X as a dataframe\n",
    "    \"\"\"\n",
    "    df[target] = pd.get_dummies(df, columns=['labels'])['labels_{}'.format(target)]\n",
    "#     df['fname'] = df['Unnamed: 0']\n",
    "#     df.set_index('fname')\n",
    "    y = df[target].values\n",
    "    X = df.drop(columns=['labels', target])\n",
    "    if fill_na == '0':\n",
    "        X = X.fillna(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = choose_target(df=df, \n",
    "                     target='Purr',\n",
    "                     fill_na='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12890</th>\n",
       "      <th>12891</th>\n",
       "      <th>12892</th>\n",
       "      <th>12893</th>\n",
       "      <th>12894</th>\n",
       "      <th>12895</th>\n",
       "      <th>12896</th>\n",
       "      <th>12897</th>\n",
       "      <th>12898</th>\n",
       "      <th>12899</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ac9e7a91.wav</td>\n",
       "      <td>1.034165</td>\n",
       "      <td>1.081409</td>\n",
       "      <td>1.219715</td>\n",
       "      <td>1.042868</td>\n",
       "      <td>1.166504</td>\n",
       "      <td>1.158957</td>\n",
       "      <td>1.249667</td>\n",
       "      <td>1.121618</td>\n",
       "      <td>1.119989</td>\n",
       "      <td>1.194605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "      <td>1.765676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac9e7a91.wav</td>\n",
       "      <td>1.229840</td>\n",
       "      <td>0.849743</td>\n",
       "      <td>1.173018</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>1.201367</td>\n",
       "      <td>1.038150</td>\n",
       "      <td>0.946473</td>\n",
       "      <td>1.080248</td>\n",
       "      <td>1.092282</td>\n",
       "      <td>1.039641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "      <td>1.766838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac9e7a91.wav</td>\n",
       "      <td>1.148532</td>\n",
       "      <td>0.970157</td>\n",
       "      <td>0.807383</td>\n",
       "      <td>1.200776</td>\n",
       "      <td>1.266151</td>\n",
       "      <td>1.138947</td>\n",
       "      <td>0.889605</td>\n",
       "      <td>0.925469</td>\n",
       "      <td>1.076378</td>\n",
       "      <td>1.071888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "      <td>1.756085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac9e7a91.wav</td>\n",
       "      <td>1.198112</td>\n",
       "      <td>0.658447</td>\n",
       "      <td>1.180605</td>\n",
       "      <td>1.040019</td>\n",
       "      <td>1.130454</td>\n",
       "      <td>0.947504</td>\n",
       "      <td>1.085755</td>\n",
       "      <td>1.079043</td>\n",
       "      <td>1.090813</td>\n",
       "      <td>1.066453</td>\n",
       "      <td>...</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "      <td>1.745653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65ae847e.wav</td>\n",
       "      <td>0.286788</td>\n",
       "      <td>0.490074</td>\n",
       "      <td>0.807862</td>\n",
       "      <td>0.545526</td>\n",
       "      <td>0.525213</td>\n",
       "      <td>0.763628</td>\n",
       "      <td>0.648102</td>\n",
       "      <td>0.584791</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0.646159</td>\n",
       "      <td>...</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "      <td>2.057137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "ac9e7a91.wav  1.034165  1.081409  1.219715  1.042868  1.166504  1.158957   \n",
       "ac9e7a91.wav  1.229840  0.849743  1.173018  0.977654  1.201367  1.038150   \n",
       "ac9e7a91.wav  1.148532  0.970157  0.807383  1.200776  1.266151  1.138947   \n",
       "ac9e7a91.wav  1.198112  0.658447  1.180605  1.040019  1.130454  0.947504   \n",
       "65ae847e.wav  0.286788  0.490074  0.807862  0.545526  0.525213  0.763628   \n",
       "\n",
       "                     6         7         8         9  ...     12890     12891  \\\n",
       "ac9e7a91.wav  1.249667  1.121618  1.119989  1.194605  ...  1.765676  1.765676   \n",
       "ac9e7a91.wav  0.946473  1.080248  1.092282  1.039641  ...  1.766838  1.766838   \n",
       "ac9e7a91.wav  0.889605  0.925469  1.076378  1.071888  ...  1.756085  1.756085   \n",
       "ac9e7a91.wav  1.085755  1.079043  1.090813  1.066453  ...  1.745653  1.745653   \n",
       "65ae847e.wav  0.648102  0.584791  0.821777  0.646159  ...  2.057137  2.057137   \n",
       "\n",
       "                 12892     12893     12894     12895     12896     12897  \\\n",
       "ac9e7a91.wav  1.765676  1.765676  1.765676  1.765676  1.765676  1.765676   \n",
       "ac9e7a91.wav  1.766838  1.766838  1.766838  1.766838  1.766838  1.766838   \n",
       "ac9e7a91.wav  1.756085  1.756085  1.756085  1.756085  1.756085  1.756085   \n",
       "ac9e7a91.wav  1.745653  1.745653  1.745653  1.745653  1.745653  1.745653   \n",
       "65ae847e.wav  2.057137  2.057137  2.057137  2.057137  2.057137  2.057137   \n",
       "\n",
       "                 12898     12899  \n",
       "ac9e7a91.wav  1.765676  1.765676  \n",
       "ac9e7a91.wav  1.766838  1.766838  \n",
       "ac9e7a91.wav  1.756085  1.756085  \n",
       "ac9e7a91.wav  1.745653  1.745653  \n",
       "65ae847e.wav  2.057137  2.057137  \n",
       "\n",
       "[5 rows x 12900 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.applymap(lambda x: abs(complex(x)))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19868, 12900)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Purr'\n",
    "df_majority = df[df['labels'] != target]\n",
    "df_minority = df[df['labels'] == target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_count = sum(df[df['labels'] != target]['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled = resample(df_minority, \n",
    "                                replace=True,\n",
    "                                n_samples=majority_count,\n",
    "                                random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = choose_target(df=df_upsampled,\n",
    "                    target=target,\n",
    "                    fill_na='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.applymap(lambda x: abs(complex(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 12900)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5000, random_state=77)\n",
    "X_train_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring\n",
    "\n",
    "def score_fitted_model(model, X_test, y_test):\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    prec = precision_score(y_test, y_preds)\n",
    "    rec = recall_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    conf = confusion_matrix(y_test, y_preds)\n",
    "    scores = {'model': model.__class__.__name__, 'accuracy': acc, 'precision': prec, \n",
    "              'recall': rec, 'f1': f1, 'conf_mat': conf}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1972            9.32s\n",
      "         2           1.0643            6.80s\n",
      "         3           0.9472            6.58s\n",
      "         4           0.8469            6.41s\n",
      "         5           0.7538            6.97s\n",
      "         6           0.6678            6.50s\n",
      "         7           0.5923            6.16s\n",
      "         8           0.5267            6.14s\n",
      "         9           0.4749            5.88s\n",
      "        10           0.4249            5.70s\n",
      "        20           0.1537            4.65s\n",
      "        30           0.0567            3.85s\n",
      "        40           0.0216            3.42s\n",
      "        50           0.0081            3.12s\n",
      "        60           0.0031            2.84s\n",
      "        70           0.0012            2.46s\n",
      "        80           0.0006            2.11s\n",
      "        90           0.0006            1.73s\n",
      "       100           0.0006            1.42s\n",
      "       200           0.0006            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=200, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=8, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=1,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                n_estimators=200,\n",
    "                                max_features=5000,\n",
    "                                 random_state=8,\n",
    "                                 verbose=1\n",
    "                                )\n",
    "gbc.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'GradientBoostingClassifier',\n",
       " 'accuracy': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1': 1.0,\n",
       " 'conf_mat': array([[ 90,   0],\n",
       "        [  0, 102]])}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fitted_model(gbc, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'RandomForestClassifier',\n",
       " 'accuracy': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1': 1.0,\n",
       " 'conf_mat': array([[ 90,   0],\n",
       "        [  0, 102]])}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fitted_model(rfc, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jared/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'LogisticRegression',\n",
       " 'accuracy': 0.9791666666666666,\n",
       " 'precision': 0.9615384615384616,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9803921568627451,\n",
       " 'conf_mat': array([[ 88,   4],\n",
       "        [  0, 100]])}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fitted_model(log, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
