{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_test_data():\n",
    "    if os.path.isfile(config.test_p_path):\n",
    "        print('Loading existing data for {} model'.format(config.mode))\n",
    "        with open(config.test_p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_feat(audio_dir):\n",
    "    tmp = check_test_data()\n",
    "    if tmp:\n",
    "        return tmp.data # a dictionary of arrays\n",
    "    fsplits = defaultdict(list)\n",
    "    print('Extracting features from audio')\n",
    "    for fn in tqdm(os.listdir(audio_dir)):\n",
    "        rate, wav = wavfile.read(os.path.join(audio_dir, fn))\n",
    "        label = fn2class[fn]\n",
    "        c = classes.index(label)\n",
    "        fsplits[fn] = []\n",
    "\n",
    "        for i in range(0, wav.shape[0] - config.step, config.step):\n",
    "            sample = wav[i:i + config.step]\n",
    "            # x = mfcc(sample, rate,\n",
    "            #             numcep=config.nfeat, nfilt=config.nfilt, nfft = config.nfft)\n",
    "            if config.feature_type == 'mels':\n",
    "                x = melspectrogram(sample, rate, n_mels=config.n_mels, n_fft=config.nfft)\n",
    "                x = librosa.power_to_db(x)\n",
    "            x = (x - config.min) / (config.max - config.min)\n",
    "            if config.mode == 'conv':\n",
    "                x = x.reshape(1, x.shape[0], x.shape[1], 1)\n",
    "            elif config.mode == 'time':\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "            fsplits[fn].append(x)\n",
    "    return fsplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predictions(audio_dir):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    fn_prob = {}\n",
    "    fsplits = build_test_feat(audio_dir)\n",
    "\n",
    "    print(\"Making predictions\")\n",
    "    for fn in tqdm(os.listdir(audio_dir)):\n",
    "        label = fn2class[fn]\n",
    "        c = classes.index(label)\n",
    "        splits = fsplits[fn]\n",
    "        y_prob = []\n",
    "        for x in splits:\n",
    "            y_hat = model.predict(x)\n",
    "            y_prob.append(y_hat)    \n",
    "            y_pred.append(np.argmax(y_hat))\n",
    "            y_true.append(c)\n",
    "        fn_prob[fn] = np.mean(y_prob, axis=0).flatten()\n",
    "    return y_true, y_pred, fn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test/roadsound_labels.csv', index_col=0)\n",
    "classes = list(np.unique(df.labels))\n",
    "fn2class = dict(zip(df.fname, df.labels))\n",
    "p_path = os.path.join('pickles', 'conv.p') ### configuration file\n",
    "with open(p_path, 'rb') as handle:\n",
    "    config = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/10epochs_20200218.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:25<00:00,  7.55it/s]\n",
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [30:21<00:00,  9.39s/it]   \n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, fn_prob = build_predictions('audio/test_roadsound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5371872451826102"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
