{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_path = os.path.join('pickles', 'conv20200218.p')\n",
    "with open(p_path, 'rb') as handle:\n",
    "    config = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 4, 16)         416       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 4, 32)         4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                53312     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 58,693\n",
      "Trainable params: 58,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d (5, 5, 1, 16)\n",
      "conv2d_1 (3, 3, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "# summarize filter shapes\n",
    "for layer in model.layers:\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # get filter weights\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filters, biases = model.layers[1].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "# plot first few filters\n",
    "n_filters, ix = 4, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = plt.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        plt.imshow(f[:, :, j], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train/roadsound_labels.csv', index_col=0)\n",
    "df.set_index('fname', inplace=True)\n",
    "for f in df.index:\n",
    "    rate, signal = wavfile.read('clean/'+f)\n",
    "    df.at[f, 'length'] = signal.shape[0]/rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_y, test_y = train_test_split(df, df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fname\n",
       "ef15f5ff.wav                         Bus\n",
       "ce1d6001.wav                  Skateboard\n",
       "c09eeca9.wav                  Skateboard\n",
       "228212bb.wav                         Bus\n",
       "5f31ab9b.wav                  Motorcycle\n",
       "                          ...           \n",
       "288ba073.wav    Race_car_and_auto_racing\n",
       "f1f0ac34.wav                         Bus\n",
       "30ad0819.wav                Bicycle_bell\n",
       "4bc5780a.wav                  Motorcycle\n",
       "099967d7.wav                Bicycle_bell\n",
       "Name: labels, Length: 222, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
